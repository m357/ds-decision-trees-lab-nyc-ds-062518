{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Game of Thrones example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generate and pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block, we generate a data set with just one variable, \"age\", to mimick our \"Game of Thrones\" tree example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "#This code is provided \n",
    "random.seed(123)\n",
    "age_0 = pd.DataFrame([19])\n",
    "age_1 = pd.DataFrame(sorted(random.sample(range(18, 50), 20)))\n",
    "age_2 = pd.DataFrame(sorted(random.sample(range(35, 70), 20)))\n",
    "age_3 = pd.DataFrame([68])\n",
    "\n",
    "age = age_0.append(age_1, ignore_index= True)\n",
    "age = age.append(age_2, ignore_index= True)\n",
    "age = age.append(age_3, ignore_index= True)\n",
    "\n",
    "\n",
    "label_1 = pd.DataFrame([1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1])\n",
    "label_2 = pd.DataFrame([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0])\n",
    "\n",
    "\n",
    "label = label_1.append(label_2, ignore_index=True)\n",
    "data = pd.concat([age, label], axis=1)\n",
    "\n",
    "data.columns = ['age', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is created in such a way that the data is not perfectly separable, and also in a way that younger people seem to be more likely to watch the show."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  label\n",
       "0   19      1\n",
       "1   19      0\n",
       "2   20      1\n",
       "3   21      0\n",
       "4   22      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  label\n",
       "37   64      0\n",
       "38   65      1\n",
       "39   67      0\n",
       "40   68      1\n",
       "41   68      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2  Manually create a split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try to manually calculate what the \"perfect split\" is for this data set, so we'll basically try to recreate the first \"split\" in the decision tree from our lab. Let's show it again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](G_of_T_tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is 41 the best split? Let's find out! You'll create 3 functions in total:\n",
    "- A function `split()` which splits up the data set in a way that you can easily compute the gini for the two \"children\" of the parent node, given a split value.\n",
    "- A function `gini_score()`, which, given a certain split, computes the gini for the left node, the gini for the right node, and the purity gain\n",
    "- A function `best_split()` which loops over the former two functions to find the best split. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating the `split()` function. This function takes three arguments, the first one is the column name, which should be a string, the second one is the value that represents the split (in this example, representing a certain age), and as a third argument the name of the data set.\n",
    "\n",
    "In the cell below, complete the `split` function. This function will take in a column name, value, and a DataFrame.  For any data in the named column less than or equal to `value` parameter, the function should store these rows in a variable called `data_left`.  Any rows with a value in `col_name` greater than `value` should be stored in `data_right`.  The function should return `data_left, data_right`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(col_name, value, data):\n",
    "    #split the data in 2 given a column name and the value\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our newly created function on the column \"age\" (for this data the only option), and look at the age 44."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6c5b1813cbeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "data_left, data_right = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, inspect `data_left` and `data_right`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gini Score\n",
    "\n",
    "Next, we'll create a function to determine the **_gini score_** for a given split.  \n",
    "\n",
    "Complete the `gini_score` function in the cell below.  Since this function is a bit complicated, comments have been provided to help simplify writing it. \n",
    "\n",
    "`gini_score` should:\n",
    "* Determine the size of each split, as well as the total number of samples.\n",
    "* Determine the probability of seeing a given outcome (watches or doesn't watch GoT) in both splits. \n",
    "* Square the probability and sum then sum the squares for a given node. \n",
    "* Calculate the gini coefficient for both splits (1 minus the value calculated in the last step)\n",
    "* Calculate the weighted gini scores for each side by multiplying the proportion of the total sample that side makes up (size of side / number of total samples).\n",
    "* Calculate the gain by adding the two weighted gini scores together.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_score(data_left, data_right):\n",
    "    \n",
    "    # amount of instances flowing in the left vs right node\n",
    "    size_left= None\n",
    "    size_right = None\n",
    "    n_samples = None\n",
    "    \n",
    "    # respective chances of seeing each outcome in the left vs right node \n",
    "    p_0L = None\n",
    "    p_1L = None\n",
    "    p_0R = None\n",
    "    p_1R = None\n",
    "    \n",
    "    #take the squares and sum over each node\n",
    "    score_L = None\n",
    "    score_R = None\n",
    "    \n",
    "    # left node and right node ginis\n",
    "    gini_L = None\n",
    "    gini_R = None\n",
    "    \n",
    "    #weighted ginis\n",
    "    weight_gini_L = None\n",
    "    weight_gini_R = None\n",
    "    \n",
    "    # The gains (here, we don't compute the root gini again. This value should be mimimized.)\n",
    "    gain = None\n",
    "    return gini_L, gini_R, gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's call our function on the split we've already made to test that everything works.  \n",
    "\n",
    "In the cell below, call `gini_score` and pass in `data_left` and `data_right`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Expected Output: (0.4444444444444444, 0.4012345679012346, 0.42592592592592593)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the Optimal Split,\n",
    "\n",
    "Now that we have a function to split our data on a given value, and another function to determine how good this split using gini score, we'll write one more function to find the split that produces the best possible gini scores,\n",
    "    \n",
    "In the cell below, complete the best split function.  As with the previous function, we have included comments to help make coding it less complicated.\n",
    "   \n",
    "The function should:\n",
    "* Determine the range of the search space (between the minimum and maximum values that column contains)\n",
    "* Iterate through that search space.  For every value:\n",
    "* Split the data using our split function\n",
    "* Calculate the for each side of the split, as well as the gain\n",
    "    * If the gain is better (lower) than the current best score, update the `best` values,\n",
    "* When every possible value in search space has been tested, return an `output` dictionary containing the best value to split on, the best gain score, the best splits, and the best gini scores for those groups. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_split(data, col_name):\n",
    "    # make sure you have the correct range to loop over\n",
    "    min_val = None\n",
    "    max_val = None\n",
    "    best_score = 999\n",
    "    # loop over all the ages \n",
    "    for i in range(min_val, max_val):\n",
    "        data_left, data_right = None\n",
    "        gini_l, gini_r, gain = None\n",
    "        # update if gain is lower than any previously observed gain \n",
    "        if None:\n",
    "            best_val = None\n",
    "            best_score = None\n",
    "            best_groups = None\n",
    "            best_ginis= None\n",
    "    output = None\n",
    "    # create a dictionary with the best value, the best gain, the best groups and the best ginis\n",
    "    output['val'] = None\n",
    "    output['gain'] = None\n",
    "    output['groups'] = None \n",
    "    output['ginis'] = None\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test that our new function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_output = best_split(data, \"age\")\n",
    "# best_output['ginis']\n",
    "# split_age = best_output['val']\n",
    "\n",
    "# split_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional\n",
    "\n",
    "Uncomment and run the cell below to get a better idea for what the `best_split` function is actually doing during each iteration of the loop. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to see what's going on in each loop...\n",
    "#min_age=19\n",
    "#max_age=68\n",
    "#for i in range(min_age, max_age):\n",
    "#        data_left, data_right = split(\"age\", i, data)\n",
    "#        data_l,data_r, gini = gini_score(data_left, data_right)\n",
    "#        print(i)   \n",
    "#        print(gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Use scikit learn and verify answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use scikit-learn to create a decision tree. \n",
    "\n",
    "Run the cell below to import the `tree` module from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a `DecisionTreeClassifier` object. When creating the tree, set the `criterion` equal to `gini`, and the `max_depth` equal to `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GoT = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use `clf.fit` with \"age\" as a first argument and \"label\" as a second argument. If you only have 1 predictor, you need to reshape your predictor using `.reshape(-1, 1)`. \n",
    "\n",
    "Run the cell below to fit our Decision Tree Classifier object to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_GoT.fit(data['age'].values.reshape(-1, 1), data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoT_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Visualize the Fitted Decision Tree\n",
    "\n",
    "Some 3rd party libraries make it easy to create a visual representation of our fitted Decision Tree Classifier.  Run the cell below to create the visualization.\n",
    "\n",
    "**_NOTE:_**  The code below relies on a library called `graphviz` which is notoriously troublesome to get working on some machines. If the code doesn't work immediately, feel free to try and debug it by googling the error message--if it doesn't work, it's probably only because you need to install a missing dependency. If you can't get the visualization to work, feel free to skip this section!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this code and run this cell to visualize the Tree\n",
    "# import graphviz \n",
    "# from sklearn.tree import export_graphviz\n",
    "# GoT_graph = tree.export_graphviz(GoT_tree, out_file=None) \n",
    "# graph = graphviz.Source(GoT_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this code and run this cell to visualize the Tree\n",
    "# export_graphviz(GoT_tree, out_file=\"mytree.dot\")\n",
    "# with open(\"mytree.dot\") as f: dot_graph = f.read()\n",
    "# graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that scikit learn generated the same split! Now, let's verify if we computed the correct gini measures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. US salaries data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The salary data set was extracted from the census bureau database and contains salary information. The goal is to use this data set and to try to draw conclusions regarding what drives salaries. More specifically, the target variable is categorical (> 50k; <= 50 k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d1/69ee7e757f657e7f527cbf500ec2d295396e5bcec873cf4eb68962c41024/statsmodels-0.9.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.4MB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: patsy in /opt/conda/lib/python3.6/site-packages (from statsmodels) (0.5.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from statsmodels) (0.23.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from patsy->statsmodels) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.4 in /opt/conda/lib/python3.6/site-packages (from patsy->statsmodels) (1.14.3)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->statsmodels) (2018.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->statsmodels) (2.7.3)\n",
      "Installing collected packages: statsmodels\n",
      "Successfully installed statsmodels-0.9.0\n",
      "Collecting scipy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 31.2MB 1.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.6/site-packages (from scipy) (1.14.3)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.1.0\n",
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/c8/8db4108aba5e2166cd2ea4eafa1a4b82f89240a1fa85733029cc2358ad1f/scikit_learn-0.19.2-cp36-cp36m-manylinux1_x86_64.whl (4.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 4.9MB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Running setup.py bdist_wheel for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/m357/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: scikit-learn, sklearn\n",
      "Successfully installed scikit-learn-0.19.2 sklearn-0.0\n",
      "Collecting seaborn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/76/220ba4420459d9c4c9c9587c6ce607bf56c25b3d3d2de62056efe482dadc/seaborn-0.9.0-py3-none-any.whl (208kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 11.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.15.2 in /opt/conda/lib/python3.6/site-packages (from seaborn) (0.23.4)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from seaborn) (1.1.0)\n",
      "Collecting matplotlib>=1.4.3 (from seaborn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/59/f235ab21bbe7b7c6570c4abf17ffb893071f4fa3b9cf557b09b60359ad9a/matplotlib-2.2.3-cp36-cp36m-manylinux1_x86_64.whl (12.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 12.6MB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /opt/conda/lib/python3.6/site-packages (from seaborn) (1.14.3)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas>=0.15.2->seaborn) (2018.5)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib>=1.4.3->seaborn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (949kB)\n",
      "\u001b[K    100% |████████████████████████████████| 952kB 23.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10 (from matplotlib>=1.4.3->seaborn)\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib>=1.4.3->seaborn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/8a/718fd7d3458f9fab8e67186b00abdd345b639976bc7fb3ae722e1b026a50/pyparsing-2.2.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 23.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.6/site-packages (from matplotlib>=1.4.3->seaborn) (1.11.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (38.4.0)\n",
      "Installing collected packages: kiwisolver, cycler, pyparsing, matplotlib, seaborn\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.0.1 matplotlib-2.2.3 pyparsing-2.2.0 seaborn-0.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels\n",
    "!pip install scipy\n",
    "!pip install sklearn\n",
    "!pip install seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels as sm\n",
    "import sklearn as skl\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.linear_model as linear_model\n",
    "import sklearn.cross_validation as cross_validation\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.tree as tree\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries = pd.read_csv(\"salaries_final.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Relationship</th>\n",
       "      <th>Race</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age   Education         Occupation Relationship   Race     Sex Target\n",
       "32556   27  Assoc-acdm       Tech-support         Wife  White  Female  <=50K\n",
       "32557   40     HS-grad  Machine-op-inspct      Husband  White    Male   >50K\n",
       "32558   58     HS-grad       Adm-clerical    Unmarried  White  Female  <=50K\n",
       "32559   22     HS-grad       Adm-clerical    Own-child  White    Male  <=50K\n",
       "32560   52     HS-grad    Exec-managerial         Wife  White  Female   >50K"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset \"salaries\" contains 6 predictors, and one outcome variable, the target salary <= 50k/ >50k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 6 predictors are:\n",
    "- `Age`: continuous.\n",
    "\n",
    "- `Education`: Categorical. Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, \n",
    "Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "\n",
    "- `Occupation`: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "\n",
    "- `Relationship`: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "- `Race`: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "- `Sex`: Female, Male."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to know that scikit learn needs to get dummies as an input for categorical variables. Luckily, we can use the `dmatrices` from the patsy library to get our data in the correct shape. From our 7 predictors, we only have 2 continuous variables (\"Age\" and \"Education-Num\"). The other 5 are all categorical.\n",
    "\n",
    "In order to deal use categorical data in the model, we'll need to **_One-Hot Encode_** the categorical data by creating boolean dummy columns for each different category in each categorical column. Pandas provides a way to do this, but we'll explore that in a further lab.  In this lab, we'll make use of the `patsy` library's `dmatrices` module. \n",
    "\n",
    "Run the cell below to split our target from the dataset, and transform our dataset into a one-hot encoded version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: patsy in /opt/conda/lib/python3.6/site-packages (0.5.0)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from patsy) (1.11.0)\r\n",
      "Requirement already satisfied: numpy>=1.4 in /opt/conda/lib/python3.6/site-packages (from patsy) (1.14.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install patsy\n",
    "from patsy import dmatrices\n",
    "target, data = dmatrices('Target ~ Age + C(Education) + \\\n",
    "                  C(Occupation) + C(Relationship) + C(Race) + C(Sex)',\n",
    "                  salaries, return_type = \"dataframe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the appropriate method to split our our data and labels into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_test,target_train, target_test = train_test_split(data, target, \n",
    "                                                                   test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.cross_validation.train_test_split(*arrays, **options)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_split"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Creating trees\n",
    "\n",
    "Now that we have prepared our data, we'll create a large Decision Tree to see how it does.\n",
    "\n",
    "In the cell below, create a `DecisionTreeClassifier` object, and set the `criterion` parameter to `'gini'`, as well as the `max_depth` parameter to `12`.\n",
    "\n",
    "Then, run the cell below it to `fit()` our model to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "sal_tree = None\n",
    "sal_tree = tree.DecisionTreeClassifier(criterion = \"gini\", max_depth = 12)\n",
    "sal_tree.fit(data_train, target_train.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in /opt/conda/lib/python3.6/site-packages (0.9)\r\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mproc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors)\u001b[0m\n\u001b[1;32m    708\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    710\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0merr_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1344\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1345\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dot': 'dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mExecutableNotFound\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/files.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(self, format)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mpipe\u001b[0;34m(engine, format, data, quiet)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[1;32m    161\u001b[0m     \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcapture_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/graphviz/backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(cmd, input, capture_output, check, quiet, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENOENT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mExecutableNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mExecutableNotFound\u001b[0m: failed to execute ['dot', '-Tsvg'], make sure the Graphviz executables are on your systems' PATH"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<graphviz.files.Source at 0x7fa8863b10f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optional: Uncomment this cell and run it to visualize our trained model. \n",
    "!pip install graphviz\n",
    "import graphviz \n",
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(sal_tree, out_file=\"mytree.dot\", feature_names=data_train.columns , class_names=list(target_train), rounded=True)\n",
    "with open(\"mytree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smaller Trees\n",
    "\n",
    "Let's examine if there's a difference with smaller trees.  \n",
    "\n",
    "In the cell below, create a Decision Tree Classifier as we did before, but this time set the `max_depth` to `3`.  Still set the `criterion` to `gini`. Then, `.fit()` the smaller model to our training data (see the cell above if you are unsure of the syntax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sal_tree_smaller = None\n",
    "# sal_tree_smaller.fit(data_train, target_train.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Uncomment this cell and run it to visualize our trained model. \n",
    "# export_graphviz(sal_tree_smaller, out_file=\"mytree.dot\", feature_names=data_train.columns ,\n",
    "#                 class_names=list(target_train), rounded=True)\n",
    "# with open(\"mytree.dot\") as f:\n",
    "#     dot_graph = f.read()\n",
    "# graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most leaf nodes will point to <= 50 k. How is this possible?\n",
    "A class imbalance in our dataset! 5865 make more than 50k, while 18555 make less (~25 vs 75%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the left nodes always point to \"true\" and the right nodes to \"false\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Model performance\n",
    "\n",
    "Now that we have trained models, let's evaluate the performance of each. \n",
    "\n",
    "Run the cell below to import the `accuracy_score` helper method.  Then, run the cell below to create some sample predictions on our testing data and generate a `confusion_matrix` and a `classification_report` based on the predictions.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5587  572]\n",
      " [ 908 1074]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.86      0.91      0.88      6159\n",
      "        1.0       0.65      0.54      0.59      1982\n",
      "\n",
      "avg / total       0.81      0.82      0.81      8141\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred= sal_tree.predict(data_test)\n",
    "print(metrics.confusion_matrix(target_test.iloc[:,1], pred))\n",
    "print(metrics.classification_report(target_test.iloc[:,1], pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8182041518241002"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(target_test.iloc[:,1], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_smaller = sal_tree_smaller.predict(data_test)\n",
    "# print(metrics.confusion_matrix(target_test.iloc[:,1], pred_smaller))\n",
    "# print(metrics.classification_report(target_test.iloc[:,1], pred_smaller))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below to generate an accuracy score for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(target_test.iloc[:,1], pred_smaller)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Tuning\n",
    "\n",
    "One of the best ways to tune Decision Trees to prevent **_overfitting_** is to pre-tune the model by providing constraints on certain aspects of the Decision Tree. Decision Trees are famously prone to overfitting, and tuning the model to be more general can help prevent this. \n",
    "\n",
    "The following parameters are the most commonly used for tuning.  In a later lab, you'll learn how to automate the search for the best parameters for each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- criterion: either gini for gini impurity, or entropy for information gain.\n",
    "- max_depth: the maximum depth of a tree.\n",
    "- min_samples_split: minimum amount of samples required to split an internal node.\n",
    "- min_samples_leaf: The minimum number of samples required to be at a leaf node.\n",
    "- class_weight: Weights associated with classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "sal_tree_tuned= tree.DecisionTreeClassifier(criterion = \"gini\",\n",
    "                                            max_depth = 12, min_samples_split = 300, min_samples_leaf = 150)\n",
    "sal_tree_tuned = sal_tree_tuned.fit(data_train, target_train.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Uncomment this cell and run it to visualize our trained model. \n",
    "# export_graphviz(sal_tree_tuned, out_file=\"mytree.dot\", feature_names=data_train.columns , \n",
    "#                 class_names=list(target_train), rounded=True)\n",
    "# with open(\"mytree.dot\") as f:\n",
    "#     dot_graph = f.read()\n",
    "# graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, run the cell below so we can see how well the pre-tuned model did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tuned = sal_tree_tuned.predict(data_test)\n",
    "print(metrics.confusion_matrix(target_test.iloc[:,1], pred_tuned))\n",
    "print(metrics.classification_report(target_test.iloc[:,1], pred_tuned))\n",
    "\n",
    "accuracy_score(target_test.iloc[:,1], pred_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this deep tree: better result with pruning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "https://www.svds.com/machine-learning-vs-statistics/ \n",
    "\n",
    "https://github.com/xbno/Projects/blob/master/Models_Scratch/Decision%20Trees%20from%20scratch.ipynb\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/\n",
    "\n",
    "https://www.valentinmihov.com/2015/04/17/adult-income-data-set/\n",
    "\n",
    "http://scikit-learn.org/stable/modules/tree.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
